---
title: "Gene Set Variation Analysis with SOMAscan"
author: "Grioni, Andrea"
date: "22/04/2020"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Settings for Internal Servers

Add Tutorial libraries to libPaths.

```{r}

libpath_local <- c("/dlab/bioinformatics/TM/TMDS3/training/share/R/session9_gsva/Rlib/", 
                   "/dlab/bioinformatics/TM/TMDS3/training/share/R/session9_gsva/Tutorials-main/R/GSVA/renv/library/R-4.0/x86_64-pc-linux-gnu")

.libPaths(libpath_local)

```


## test renv

```{r renv}
if (!requireNamespace("renv", quietly = TRUE))
   install.packages("renv")
if (!requireNamespace("glue", quietly = TRUE))
    install.packages("glue", lib=libpath_local)
# if (!requireNamespace("BiocManager", quietly=TRUE, lib.loc=libpath_local))
#   install.packages("BiocManager")
# if (!requireNamespace("org.Hs.eg.db", quietly = TRUE, lib.loc=libpath_local))
#     BiocManager::install("org.Hs.eg.db", lib=libpath_local)

library(renv)
library(glue)

Sys.setenv(RENV_PATHS_LOCAL = glue("{getwd()}/renv/local"))
options(connectionObserver = NULL) # fix current bug in RSQL. see https://support.bioconductor.org/p/9136239/
renv::restore()

#install.packages('plyr', repos = 'https://cloud.r-project.org')
#install.packages("gridExtra", repos = 'https://cloud.r-project.org')

## ERROR: compilation failed for package ‘XVector’
# sudo apt-get install libz-dev
## ERROR: libxml2.so.2: cannot open shared object file: No such file or directory
# sudo apt-get install libxml2

## ERROR: compilation failed for package ‘readr’
#install.packages("Rcpp", repos="https://rcppcore.github.io/drat")

```
# Gene Set Variation Analysis

Gene Set Variation Analysis (GSVA) is a non-parametric, unsupervised method for estimating variation of gene set enrichment through the samples of a expression data set. GSVA performs a change in coordinate systems, transforming the data from a gene by sample matrix to a gene-set by sample matrix, thereby allowing the evaluation of pathway enrichment for each sample. This new matrix of GSVA enrichment scores facilitates applying standard analytical methods like functional enrichment, survival analysis, clustering, CNV-pathway analysis or cross-tissue pathway analysis, in a pathway-centric manner.

Author: Justin Guinney [aut, cre], Robert Castelo [aut], Alexey Sergushichev [ctb], Pablo Sebastian Rodriguez [ctb]
Citation: [publication_link](https://doi.org/10.1186/1471-2105-14-7)

#```{r installation, error=FALSE, message=FALSE, warning=FALSE, echo=TRUE, results='hide'}
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")

#if (!requireNamespace("GSVA", quietly = TRUE))
#    BiocManager::install("GSVA")
#```

# Load libraries

The notebook requires the packages `GSVA`, `GSEABase`, `Biobase`, `geneFilter`, `limma`, `tidyverse`, `glue`, and the `SOMAscan.db` annotation package.
Link to `somascan.db` package (here)[https://bitbucket.prd.nibr.novartis.net/users/grionan1/repos/somadb/]

```{r load_datasets, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(GSVA)
library(GSEABase)
library(Biobase)
library(genefilter)
library(limma)
library(tidyverse)
library(glue)
library(gridExtra)
library(SomaDataIO)
library(ggplot2)
library(fs)
library(tidyverse)
library(plyr)
library(gplots)
library(RColorBrewer)
library(somascan.db)
```
## Helper functions

Define helper functions

```{r set_checkpoint, echo=FALSE}
# this block eval code during execution.
checkpoint <- function(n, expression, message) {
  if (!expression) {
    print(glue("[checkpoint_{n}]\tFAILED\t{message}"))
    stop(glue("checkpoint_{n} failed"))
  } else {
    print(glue("[checkpoint_{n}]\tPASS\t{message}"))
  }
}

# write table out with log file
write_out <- function(table, outdir, name) {
  print(glue("[FILE]\twrite {name} to:\t{outdir}"))
  table %>% write_csv(fs::path(outdir, name))
  }

# concatenate tibbles
update_discarded <- function(table_in, flag, table=NULL) {
  table_in <- table_in %>% add_column(QC_flag=flag)
  if (!is.null(table)){
    table <- table %>% bind_rows(table_in)
    return(table)
  } else {
    return(table_in)
    }
  }
```


# Extract Data Archive

Toy Dataset will be extracted in the working directory.

```{r}
unzip(glue("{str_replace(getwd(), 'R/GSVA', '')}/datasets/gsva/gsva_dataset.zip"))
```

# Data Path

Set path to datasets

```{r}
# absolute path to data folder
datapath <- glue("{getwd()}/gsva_dataset")
clinical_filename <-"hsa05212_pancreatic_cancer_insilico_clinical.csv"
adat_filename <- "hsa05212_pancreatic_cancer_insilico.adat"
gmt_filename <- "signature.somamers.cleaned.gmt"
output_dir <- "./"

clinical_sampleid_colname <- "SampleId"
```

## build path
```{r}
datapath <- fs::path(datapath)
clinical_filepath <- fs::path(datapath, clinical_filename)
adat_filepath <- fs::path(datapath, adat_filename)
gmt_filepath <- fs::path(datapath, gmt_filename)
output_dir <- fs::path(output_dir)
fs::dir_create(output_dir)
```


# PreProcessing

## Data Load and Cleaning

Function reads adat file.

adat file is loaded with [SomaDataIO](https://github.com/SomaLogic/SomaDataIO)
SomaDataIO is an R package for reading adat files developed by SomaLogic.
SomaDataIO works with adat files generated by Somascan v.4+

```{r load_adat_data, echo=FALSE}
print(glue("load adat {path_file(adat_filepath)} with SomaDataIO tool"))
adat_table <- SomaDataIO::read_adat(adat_filepath) 
print(glue("[STAT]\tadat table dim is:\t{paste(dim(adat_table), collapse='x')}"))
```

## Reading Clinical Data

```{r load_clinical_data}
print(glue("load clinical table {clinical_filename}"))

if (str_detect(clinical_filename, ".csv$")) {
  clinical_table <- read_csv(
    clinical_filepath,
    guess_max = 15000, col_types = cols()) # col_types = cols() suppress messages  
} else if (str_detect(clinical_filename, ".tsv$")) {
  clinical_table <- read_tsv(
    clinical_filepath,
    guess_max = 15000, col_types = cols()) # col_types = cols() suppress messages  
}

print(glue("clinical table dim is {paste(dim(clinical_table), collapse='x')}"))
```

## Merge ADAT and Clinical Table

Chunk merge ADAT with Clinical Table

```{r digest_adat, echo=FALSE}
digested_adat <- list()

print(glue("convert SeqId notation of Annotation class to format 'seq.' + 'SeqId' + '.' + 'SeqId Version'"))
digested_adat$annotation <- attributes(adat_table)$Col.Meta %>% 
  as_tibble %>% 
  mutate(SeqId=str_replace(`SeqId`, "^", "seq.")) %>% 
  mutate(SeqId=str_replace(`SeqId`, "-", "\\."))
print(glue("move calibrator to named list"))
digested_adat$calibrators <- adat_table %>% filter(SampleType=="Calibrator") %>% 
  as_tibble
print(glue("move Samples to named list"))
digested_adat$samples <- adat_table %>% filter(SampleType=="Sample") %>% 
  as_tibble
print(glue("move others SampleType to named list"))
digested_adat$others <- adat_table %>% 
  filter(!str_detect(SampleType, "Sample|Calibrator")) %>% 
  as_tibble
print(glue("move Metadata to named list"))
digested_adat$clinical <- clinical_table
print(glue("attach metadata to SOMAscan measuraments by Sample Id"))
digested_adat$complete <- inner_join(
  digested_adat$samples, digested_adat$clinical, 
  by= c("SampleId" = clinical_sampleid_colname))
digested_adat$discarded <- anti_join(
  digested_adat$samples, digested_adat$clinical,
  by= c("SampleId" = clinical_sampleid_colname))

digested_adat$discarded <- update_discarded(
  table_in=digested_adat$discarded,
  flag="unmatch")

print(glue("[STAT]\tadat table samples x aptamers:\t{paste(dim(digested_adat$samples), collapse='x')}"))
print(glue("[STAT]\tadat table calibrator x aptamers:\t{paste(dim(digested_adat$calibrators), collapse='x')}"))
print(glue("[STAT]\tadat table others [Buffer,QC] x aptamers:\t{paste(dim(digested_adat$others), collapse='x')}"))
print(glue("[STAT]\tadat+metadata dim:\t{paste(dim(digested_adat$complete), collapse='x')}"))
print(glue("[STAT]\tadat+metadata no match:\t{paste(dim(digested_adat$discarded), collapse='x')}"))

write_out(digested_adat$annotation, output_dir, 'annotation_v4.1.csv')


if (dim(digested_adat$discarded)[[1]] != 0) {
  print(glue( "[STAT]\tSampleIDs adat+metadata no match:\t{paste(digested_adat$discarded %>% pull(SampleId), collapse=',')}"))
  write_out(digested_adat$discarded, output_dir, 'adat_metadata_no_match.csv')
  }
```

## free memory

```{r}
rm(adat_table, clinical_table) 
```


### Preprocessing

SOMAlogic Quality Control (QC) pipeline evaluates the quality of both aptamers and samples.

In the `adat` table, `ColCheck` column refears to QC on aptamers, and it can have values of "FLAG" or "PASS".
In the `adat` table, `RowCheck` column refears to QC on Samples, and it can have values of "FLAG" or "PASS".

This block of code drops samples that did not pass the SOMAlogic QC ( column `RowCheck` == "FLAG").
This block of code drops aptamers that are not human (column `Organism` != "Human").

Note that:
Flagged Human aptamers (column `ColCheck` == "FLAG") are not filtered, but a table with human aptamers that did not pass the QC is saved in the `output_dir` folder.
The SOMAlogic QC is calibrate on healthy human samples and for this reason this pipeline do not remove FLAGGED aptamers.

e.g. In cancer, we expect over-expression of several proteins that are not over-expressed in healthy control.
Therefore, it can be that the QC of SOMAlogic will FLAG those proteins because they are above the normality (healthy population).

#### Check SomaLogic Flagged Samples

```{r samples_cleanup, echo=FALSE}
sample_rowcheck <- TRUE # remove flagged samples
export_failed <- TRUE # save flagged samples/aptamers
remove_flag_samples <- TRUE # remove flagged samples

if (sample_rowcheck) {
  samples_qc_flag <- digested_adat$complete %>% 
    filter(RowCheck == 'FLAG') %>%
    pull(SampleId)
  
  samples_qc_pass <- digested_adat$complete %>% 
    filter(RowCheck == 'PASS') %>%
    pull(SampleId)

  print(glue( "[STAT]\ttotal samples passed SomaLogic QC:\t{samples_qc_pass %>% length()}"))
  print(glue( "[STAT]\ttotal samples flagged SomaLogic QC:\t{samples_qc_flag %>% length()}"))
  
  if ( !is_empty(samples_qc_flag) ) {
    # print SamplesIDs of flagged samples to log file
    print(glue( "[STAT]\tSampleIDs of flagged SomaLogic QC:\t{paste(samples_qc_flag, collapse=',')}"))

  }
  
  if (remove_flag_samples) {
    # remove flagged samples from analysis
    write_out(
      digested_adat$complete %>% 
        filter(RowCheck == "FLAG"),
      output_dir,
      "human_samples_flag.csv"
    )
    
    digested_adat$discarded <- update_discarded(
      table=digested_adat$discarded,
      table_in=digested_adat$complete %>% 
        filter(RowCheck == "FLAG"), 
                      flag="RowCheck")

    print(glue("{samples_qc_flag %>% length()} samples dropped from analysis:\tRowCheck == FLAG"))
    digested_adat$complete %<>% filter(RowCheck == 'PASS')
    print(glue("{samples_qc_pass %>% length()} samples accepted for analysis:\tRowCheck == PASS"))
  }

} else {
  print(glue("skipping sample rowcheck QC"))
  samples_qc_flag <- NULL
}

```

#### Check SomaLogic Flagged Aptamers

```{r aptamers_cleanup, echo=FALSE}
print(glue( "[STAT]\ttotal aptamers:\t{digested_adat$annotation %>% pull(SeqId) %>% length()}"))

non_human_aptamers <- digested_adat$annotation %>% 
  filter(Organism != "Human") %>% 
  pull(SeqId)

print(glue("[STAT]\ttotal non-human aptamers:\t{non_human_aptamers %>% length()}"))

human_aptamers_pass <- digested_adat$annotation %>% 
  filter(ColCheck=="PASS", Organism=="Human") %>%
  pull(SeqId)

print(glue("[STAT]\ttotal human aptamers pass QC:\t{human_aptamers_pass %>% length()}"))

human_aptamers_flag <- digested_adat$annotation %>% 
  filter(ColCheck=="FLAG", Organism=="Human") %>%
  pull(SeqId)

print(glue("[STAT]\ttotal human aptamers flag QC:\t{human_aptamers_flag %>% length()}"))
print(glue("[STAT]\ttotal human aptamers accepted:\t{length(c(human_aptamers_flag, human_aptamers_pass))}"))

write_out(digested_adat$annotation %>% filter(ColCheck=="FLAG", Organism=="Human"),
          output_dir,
          "human_seqid_flag.csv")

if (!is_empty(non_human_aptamers)) {
  print(glue("remove non human aptamers from annotation and measuraments"))
  digested_adat$annotation %<>% filter(!str_detect(SeqId, paste(non_human_aptamers, collapse="|")))
  print(glue("[STAT]\tSeqId in annotation:\t{digested_adat$annotation %>% pull(SeqId) %>% length()}"))
  digested_adat$complete %<>% dplyr::select(!all_of(non_human_aptamers))
  print(glue("[STAT]\tSeqId in measuraments:\t{digested_adat$complete %>% select(starts_with('seq.')) %>% length()}"))
  digested_adat$calibrators %<>% dplyr::select(!all_of(non_human_aptamers))
  print(glue("[STAT]\tSeqId in calibrators:\t{digested_adat$calibrators %>% select(starts_with('seq.')) %>% length()}"))
  digested_adat$samples %<>% dplyr::select(!all_of(non_human_aptamers))
  print(glue("[STAT]\tSeqId in samples:\t{digested_adat$calibrators %>% select(starts_with('seq.')) %>% length()}"))
}
```

```{r}
# storing table dim for future checkpoint evals
digested_adat$raw_dim <- dim(digested_adat$complete)
# running first checkpoint
checkpoint_1 <- (digested_adat$annotation %>% pull(SeqId) %>% length() == digested_adat$complete %>% dplyr::select(starts_with('seq.')) %>% colnames() %>% length() ) 
checkpoint(n='1a', expression = checkpoint_1, message = glue("length SeqId in annotation == length SeqId in table"))
# running first checkpoint
checkpoint_1 <- (digested_adat$annotation %>% pull(SeqId) %>% length() == digested_adat$calibrators %>% dplyr::select(starts_with('seq.')) %>% colnames() %>% length() ) 
checkpoint(n='1b', expression = checkpoint_1, message = glue("length SeqId in annotation == length SeqId in calibrators"))
```

### Intro to Expression Set BioBase

Biobase is part of the Bioconductor project, and is used by many other packages. Biobase
contains standardized data structures to represent genomic data. The ExpressionSet class is
designed to combine several different sources of information into a single convenient structure.
An ExpressionSet can be manipulated (e.g., subsetted, copied) conveniently, and is the input
or output from many Bioconductor functions. 

The data in an ExpressionSet is complicated, consisting of expression data from microarray experiments 
(assayData; assayData is used to hint at the methods used to access different data components, as we will see below), 
‘meta-data’ describing samples in the experiment (phenoData), annotations and meta-data about the features 
on the chip or technology used for the experiment (featureData, annotation), information related to the protocol 
used for processing each sample (and usually extracted from manufacturer files, protocolData),
and a flexible structure to describe the experiment (experimentData). 

The ExpressionSet class coordinates all of this data, so that you do not usually have to worry about the details. 
However, an ExpressionSet needs to be created in the first place, and creation can be complicated.

Source from [here](https://www.bioconductor.org/packages/release/bioc/vignettes/Biobase/inst/doc/ExpressionSetIntroduction.pdf)

```{r}

make_eset <- function(table, annotation) {
  matrix_data <- table %>% 
    select(starts_with("seq.")) %>%
    as.matrix() %>%
    t()
  
  pheno_data <- table %>% 
    select(!starts_with("seq."))
  
  k <- annotation %>% pull(SeqId)
  
  featuresSet <- digested_adat$annotation %>% 
    filter(str_detect(SeqId, paste0(k, collapse = "|"))) %>% 
    select(EntrezGeneID, SeqId) %>% 
    mutate(PROBEID=SeqId)
  featuresSet['EntrezGeneSymbol'] <- annotation %>% pull(EntrezGeneSymbol)
  featuresSet['TargetFullName'] <- annotation %>% pull(TargetFullName)
  featuresSet <- featuresSet %>% as.data.frame()
  
  row.names(featuresSet) <- k
  
  # create expression set object
  eset <- ExpressionSet(
            assayData = matrix_data,
            phenoData = AnnotatedDataFrame(pheno_data),
            featureData = AnnotatedDataFrame(featuresSet)
  )
  return(eset)
  }
```

### Freeze Color Code

This block fix color code to be used in ggplot2 when aes(color or fill) is used with variable `ARMCD`.

usage:

* for aes(fill): `ggplot() + geom_something() + scale_fill_manual(values=colors_fix)`
* for aes(color): `ggplot() + geom_something() + scale_color_manual(values=colors_fix)`

```{r fix_color_code}
print(glue("freezing color code for variable ARM"))
colors_fix = setNames(object = scales::hue_pal()(digested_adat$complete %>% 
                                                   pull(ARM) %>% 
                                                   unique() %>% 
                                                   length()), nm = digested_adat$complete %>% 
                        pull(ARM) %>% 
                        unique())
```


### Transformation and Normalization

This code will use `limma` package to perform quantile normalization (global normalization method).

This step is dependent on the above evaluation for quantile normalization provided by `quantro`.
The quantroStat results in `3.09937` with significant p-value. It means that the variability within groups
is small relatively to the variability between groups. Therefore, we can do quantile normalization without 
breaking/removing the biological signal.

The block will convert raw values to log2, then it will apply quantile normalization.

Normalization can be run with two candidate methods: `quantile` and `cyclic loess`.
Quantile and cyclic loess normalization was originally proposed by [Bolstad et al. - 2003](https://doi.org/10.1093/bioinformatics/19.2.185)
for Affymetrix-style single-channel arrays.

1.  Quantile normalization forces the entire empirical distribution of each column to be identical.
2.  Cyclic loess normalization applies loess normalization to all possible pairs of arrays, usually cycling through all pairs several times.

Cyclic loess is slower than quantile, but allows probe-wise weights and is more robust to unbalanced differential expression.

```{r log_transform, message=FALSE, warning=FALSE, echo=FALSE, fig.width=32, fig.height=20}
log2_transform = TRUE
normalize_limma = TRUE
norm_method = 'quantile'

plot_distribution <- function (table, title=NULL, colors_fix=NULL, color_by=NULL) {
  table %>% 
  select(starts_with('seq.'), `color_by` ) %>%
  pivot_longer(!`color_by`) %>% 
  ggplot() + 
    geom_density(aes_string(x="value", color=color_by )) + 
    ggtitle(glue({title})) + 
    xlab("intensity") + ylab("density") + 
    scale_color_manual(values=colors_fix)
}

print(glue("render distribution plot of raw RFU values"))

raw <- plot_distribution(digested_adat$complete, title="Distribution in raw RFU", color_by="ARM", colors_fix=colors_fix)
ggsave(path=output_dir, plot=raw, filename = "rawRFU_displot.png")

if (log2_transform){
  print(glue("do log2 transformatio on raw RFU values"))
  digested_adat$complete_log2 <- digested_adat$complete %>% mutate_at(.vars = vars(starts_with('seq.')), base::log2)
  log2 <- plot_distribution(digested_adat$complete_log2, title="Distribution in log2(RFU)",
                    color_by="ARM", colors_fix=colors_fix) 
  ggsave(path=output_dir, plot=log2, filename = "logRFU_displot.png")
  digested_adat$complete_log2 %>%
    write_csv(fs::path(output_dir, "somascan_qc_log2.csv" ))
}

if (normalize_limma) {
  eset <- make_eset(digested_adat$complete_log2, digested_adat$annotation)

  print(glue("do quantile normalization with limma"))
  log2_norm_table <- normalizeBetweenArrays(exprs(eset), method=norm_method)
  log2_norm_table <- log2_norm_table %>% t() %>% as_tibble()
  digested_adat$postprocess <- bind_cols(pData(eset), log2_norm_table)
  
  norm <- plot_distribution(digested_adat$postprocess, 
                            title="Distribution log2 Limma quantile Norm", 
                            color_by="ARM", 
                            colors_fix=colors_fix
                            )
  
  ggsave(path=output_dir, plot=norm, filename = "logRFU_limma_norm_displot.png")

  digested_adat$postprocess %>%
    write_csv(fs::path(output_dir, "somascan_qc_log2_norm.csv" ))
}

multigrid <- grid.arrange(raw, log2, norm, nrow = 3)

ggsave(path=output_dir, filename = "rfu_transformation.png", plot=multigrid, width=32, height=20)
```

# GSVA

### load data

This block will load annotation, and the QC-corrected SOMAscan datasets as `aptamers_annotation` and `mgh_adat` variables.

The `mgh_adat` dataset is filtered to keep only baseline samples (from both COVID+ and COVID- class).

```{r load_data, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}

demo_set <- read_csv(fs::path(output_dir, "somascan_qc_log2_norm.csv"))

demo_set %>% head(10)
```

### Generate eset for aptamers
This block generates the `ExpressionSet` object required to the analysis.  
The `ExpressionSet` R object is a matrix that has rows as aptamers and sampels as cols.  
NB: `ExpressionSet` expects an `AnnotationDbi` object matching each `SeqId` to the annotation from the `SOMAscan.db` package.  

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}

aptamers <- demo_set %>% dplyr::select(starts_with("seq.")) %>% as.matrix() %>% t()
colnames(aptamers) <- demo_set$SampleId
phenoData <- AnnotatedDataFrame(demo_set %>% dplyr::select(!starts_with("seq.")) %>% as.data.frame())
rownames(phenoData) <- demo_set$SampleId

if (!identical(colnames(aptamers), rownames(phenoData))) print(glue("check input"))

# generate expression set with metadata
minimalSet <- ExpressionSet(
  assayData=aptamers,
  phenoData=phenoData,
  annotation="somascan.db")

if (!identical(colnames(aptamers), colnames(exprs(minimalSet)))) print(glue("error ExpressionSet inputs"))

if (!identical(rownames(phenoData), rownames(pData(minimalSet)))) print(glue("error ExpressionSet inputs"))

if (!identical(colnames(exprs(minimalSet)), rownames(pData(minimalSet)))) print(glue("error ExpressionSet inputs"))

```

## One-step filtering

We carry out a non-specific filtering step by discarding the 25% of the `probesets` with smaller variability,
`probesets` without `Entrez ID` annotation, `probesets` whose associated `Entrez ID` is duplicated
in the annotation, and `Affymetrix` quality control probes:

If raise error, please run:

`options(connectionObserver = NULL) # fix current bug in RSQL. see https://support.bioconductor.org/p/9136239/`
and then
`library(somascan.db)`

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
filtered_eset <- nsFilter(
  minimalSet,
  require.entrez=TRUE,
  remove.dupEntrez=TRUE,
  var.func=IQR,
  var.filter=TRUE,
  var.cutoff=0.05,
  filterByQuantile=TRUE)

minimalSet_eset <- filtered_eset$eset
minimalSet_eset

identical(colnames(exprs(minimalSet_eset)), rownames(pData(phenoData)))
```
## Prepare Expression Sets

Expression Sets can be downloaded from the [BroadInstitute](https://www.gsea-msigdb.org/gsea/msigdb/collections.jsp).

In this example, we selected the Hallmark gene sets. It summarizes and represents specific well-defined biological states or processes and display coherent expression. These gene sets were generated by a computational methodology based on identifying overlaps between gene sets in other MSigDB collections and retaining genes that display coordinate expression. 

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
## load the Expression Sets.
gsc <- GSEABase::getGmt(
  gmt_filepath,
  collectionType=NullCollection(),
  geneIdType=EntrezIdentifier())
```

### show first gene set

```{r}
geneIds(gsc[1])
```

### Functional Enrichment

The calculation of GSVA enrichment scores is performed in one single call to the gsva() function.
However, one should take into account that this function performs further non-specific filtering steps prior to the actual calculations. On the one hand, it matches gene identifiers between gene sets and gene expression values. On the other hand, it discards gene sets that do not meet minimum and maximum gene set size requirements specified with the arguments min.sz and max.sz, respectively, which, in the call below, are set to 10 and 500 genes. Because we want to use limma on the resulting GSVA enrichment scores, we leave deliberately unchanged the default argument mx.diff=TRUE to obtain approximately normally distributed ES.

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
minimalSet_es <- gsva(
  minimalSet_eset, gsc, annotation=somascan.db,
  min.sz=10, max.sz=500, verbose=TRUE, method='gsva')
```
```{r}
# show replacement
exprs(minimalSet_es)
dim(exprs(minimalSet_es))
```


We test whether there is a difference between the GSVA enrichment scores from each pair of phenotypes
using a simple linear model and moderated t-statistics computed by the limma package using an empirical Bayes shrinkage method (see Smyth, 2004).
We are going to examine both, changes at gene level and changes at pathway level and since, as we shall see below, there are plenty of them, 
we are going to employ the following stringent cut-offs to attain a high level of statistical and biological significance:

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
# set threshold
adjPvalueCutoff <- 0.05
# create design
design <- model.matrix( ~ 0 + ARM + AGE + BMI, data = pData(minimalSet_es))

# fit the model
fit <- lmFit(minimalSet_es, design)
cm <- makeContrasts(
  TRTvsPBO = ARMtreatment - ARMplacebo,
  levels = design
)
fit.cm <- contrasts.fit(fit, contrasts = cm)
# correct
fit <- eBayes(fit.cm)
# gather table of whole geneSets
allGeneSets <- topTable(fit, coef="TRTvsPBO", number=Inf)
# print basic results by filtering non significant genesets.
res <- decideTests(
  fit,
  p.value=adjPvalueCutoff
  )
summary(res)
```

```{r}
allGeneSets %>% as_tibble %>% add_column('GeneSet' = rownames(allGeneSets), .before='logFC') %>% arrange(adj.P.Val)
```

```{r, fig.width=30, fig.height=30}
sigPathways <- topTable(fit, coef=1, number=Inf, p.value=0.05, adjust="BH")
sigPathways <- sigPathways[abs(sigPathways$logFC)>0.2,]
res <- decideTests(fit, p.value=0.05)

#Create an object that can easily be written to disc
wObject <- data.frame(rownames(sigPathways), sigPathways)
colnames(wObject) <- c("Pathway","Log2FoldChange","MeanExpression","tStat","Pvalue","AdjustedPval","Bvalue")

#Filter the GSVA object to only include significant pathways
minimalSet_es <- minimalSet_es[rownames(sigPathways),]

#Set colour for heatmap
myCol <- colorRampPalette(c("dodgerblue", "black", "yellow"))(100)
myBreaks <- seq(-1.5, 1.5, length.out=101)
heat <- t(scale(t(exprs(minimalSet_es))))

ColSideColors_vector <- if_else(demo_set %>% pull(ARM) == 'placebo', 
    colors_fix[['placebo']], colors_fix[['treatment']])

heatmap.2(heat,
  col=myCol,
  breaks=myBreaks,
  main="Heatmap Placebo vs Treatment", 
  key=TRUE, 
  keysize=0.5, 
  key.title="", 
  ColSideColors=ColSideColors_vector,
  #RowSideColors=RowSideColors_vector,
  key.xlab="Enrichment Z-score", 
  scale="none", 
  density.info="none", 
  reorderfun=function(d,w) reorder(d, w, agglo.FUN=mean), 
  trace="none", 
  cexRow=3.0, 
  cexCol=2.0, 
  distfun=function(x) dist(x, method="euclidean"), 
  hclustfun=function(x) hclust(x, method="ward.D2"),
  margins=c(10,60))

```

